{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Logistic Regression on a Synthetic Classification Dataset\n",
    "\n",
    "1. Generate synthetic binary classification data with 5 features (100 samples).\n",
    "2. Train a logistic regression model using scikit-learn.\n",
    "3. Evaluate the model using accuracy, confusion matrix, and ROC AUC.\n",
    "4. Visualize decision boundary (for 2D projection).\n",
    "5. Discuss feature importance and model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Generate Synthetic Classification Data\n",
    "`make_blobs` from `sklearn.datasets` generates synthetic data; see https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Generate binary classification data using make_blobs\n",
    "X, y = make_blobs(n_samples=100, centers=2, n_features=5, cluster_std=1.5, random_state=0)\n",
    "\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"First 5 samples of X:\\n\", X[:5])\n",
    "print(\"First 5 labels y:\\n\", y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train model\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model coefficients:\", clf.coef_)\n",
    "print(\"Intercept:\", clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) (Optinal) Visualize Decision Boundary (2D Projection)\n",
    "Here we used `PCA` for reducing the dimension of the data to 2; we will study `PCA` in more details later in the course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce to 2D for visualization\n",
    "pca = PCA(n_components=2) \n",
    "X_vis = pca.fit_transform(X)\n",
    "\n",
    "clf_vis = LogisticRegression().fit(X_vis, y)\n",
    "\n",
    "# Plot decision boundary\n",
    "xx, yy = np.meshgrid(np.linspace(X_vis[:,0].min(), X_vis[:,0].max(), 100),\n",
    "                     np.linspace(X_vis[:,1].min(), X_vis[:,1].max(), 100))\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "probs = clf_vis.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, probs, 25, cmap=\"RdBu\", alpha=0.8)\n",
    "plt.scatter(X_vis[:, 0], X_vis[:, 1], c=y, cmap=\"summer\", edgecolors='k')\n",
    "plt.title(\"Logistic Regression Decision Boundary (PCA Projection)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Discussion\n",
    "- Coefficients indicate feature importance.\n",
    "- Consider regularization or feature selection for high-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
