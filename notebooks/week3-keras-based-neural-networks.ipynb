{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e0ac81",
   "metadata": {},
   "source": [
    "# Keras Neural Network Framework for Classification and Regression\n",
    "**Multi‐Task**: Classification on Pima Diabetes & Regression on Energy Efficiency\n",
    "\n",
    "Modify the `TASK` variable in the next cell to switch between modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0a0091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Panel\n",
    "TASK = 'classification'  # 'classification' or 'regression'\n",
    "HIDDEN_UNITS = 64\n",
    "DROPOUT_RATE = 0.5\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1084a31f",
   "metadata": {},
   "source": [
    "## Core Imports\n",
    "- NumPy, pandas for data\n",
    "- scikit‐learn for splits & metrics\n",
    "- standalone Keras for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f7322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "# silence C++ INFO and WARNING messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'   # 0 = all, 1 = filter INFO, 2 = filter WARNING, 3 = filter ERROR\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# Keras imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from keras.utils import set_random_seed\n",
    "\n",
    "# fix random seeds\n",
    "set_random_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5630063c-5879-4e65-b20c-9f7714ad72f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # Metric to monitor (validation loss)\n",
    "    patience=20,           # Number of epochs with no improvement before stopping\n",
    "    restore_best_weights=True  # Restores model weights from the epoch with best performance\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ac861a",
   "metadata": {},
   "source": [
    "## Data Loader\n",
    "- Loads Pima (classification) or Energy (regression)\n",
    "- Standardizes features\n",
    "- Returns train/test splits\n",
    "\n",
    "**Note:** Here the datasets are loaded directly from the web. You can also load the same data using the datasets from the other two exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389441f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(seed=42):\n",
    "    if TASK=='classification':\n",
    "        data = pd.read_csv(\"../datasets/pima-indians-diabetes.csv\", header=None)\n",
    "        \n",
    "        # Separate features (all columns except last) and target (last column)\n",
    "        X = data.iloc[:, :-1].values\n",
    "        y = data.iloc[:, -1].values\n",
    "    else:\n",
    "        data = pd.read_csv('../datasets/ENB2012_data.csv', header=None)\n",
    "        \n",
    "        # Feature engineering recommendations would go here\n",
    "        # (e.g., feature scaling, outlier handling)\n",
    "        \n",
    "        # Separate features and targets\n",
    "        X = data.iloc[:, 0:8].values\n",
    "        y = data.iloc[:, 8:10].values  # Both heating and cooling loads\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f6a287",
   "metadata": {},
   "source": [
    "## Model Builder\n",
    "- Creates a Sequential Keras model\n",
    "- Adjusts last layer & loss for task \n",
    "- `HIDDEN_UNITS` is the width of the first hidden layer, say 64 neurons.  Using `HIDDEN_UNITS//2` (i.e.\\ 32) in the next layer creates a “funnel” architecture:  \n",
    "     $$\n",
    "       8\\;\\xrightarrow{\\rm relu}\\;64\\;\\xrightarrow{\\rm relu}\\;32\\;\\xrightarrow{}1\n",
    "     $$\n",
    "  This reduces parameter count (fewer weights → less overfitting) and encourages the network to compress features gradually.  You could use the same width twice, but halving is a common heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ef06c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(HIDDEN_UNITS, activation='relu'))\n",
    "    model.add(Dropout(DROPOUT_RATE))\n",
    "    model.add(Dense(HIDDEN_UNITS//2, activation='relu'))\n",
    "    \n",
    "    if TASK=='classification':\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        loss = BinaryCrossentropy()\n",
    "        metrics = ['accuracy']\n",
    "    else:\n",
    "        model.add(Dense(2, activation='linear'))\n",
    "        loss = MeanSquaredError()\n",
    "        metrics = ['mse']\n",
    "    model.compile(optimizer=Adam(LEARNING_RATE), loss=loss, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1fc694",
   "metadata": {},
   "source": [
    "## Training & Evaluation\n",
    "- Fits model on train split\n",
    "- Evaluates on test split\n",
    "- Plots training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123223b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(seed=42):\n",
    "    X, y = load_data(seed=seed)\n",
    "\n",
    "    # Splitting data\n",
    "    Xtr,Xte,ytr,yte = train_test_split(X,y,test_size=0.3,random_state=seed)\n",
    "\n",
    "    # Scaling the daatset\n",
    "    scaler = StandardScaler().fit(Xtr)\n",
    "    Xtr = scaler.transform(Xtr)\n",
    "    Xte = scaler.transform(Xte)\n",
    "\n",
    "    # build the model\n",
    "    mdl = build_model(Xtr.shape[1])\n",
    "    hist = mdl.fit(Xtr,ytr,\n",
    "                   validation_split=0.2, # data is split into training and validation\n",
    "                   epochs=EPOCHS,\n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   callbacks=[early_stopping],  # Add the callback here for early stopping. Remove this line for no early stopping.\n",
    "                   verbose=1)\n",
    "    print(\"\\nEvaluation:\")\n",
    "\n",
    "    # prediction on test data\n",
    "    if TASK=='classification':\n",
    "        ypred = (mdl.predict(Xte)>0.5).astype(int)\n",
    "        print(\"Accuracy:\",accuracy_score(yte,ypred))\n",
    "    else:\n",
    "        ypred = mdl.predict(Xte)\n",
    "        print(\"MSE:\",mean_squared_error(yte,ypred))\n",
    "        \n",
    "    # plot\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(hist.history['loss'],label='train')\n",
    "    plt.plot(hist.history['val_loss'],label='val'); plt.legend(); plt.title('Loss')\n",
    "    if TASK=='classification':\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(hist.history['accuracy'],label='train')\n",
    "        plt.plot(hist.history['val_accuracy'],label='val'); plt.legend(); plt.title('Accuracy')\n",
    "    else:\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(hist.history['mse'],label='train')\n",
    "        plt.plot(hist.history['val_mse'],label='val'); plt.legend(); plt.title('MSE')\n",
    "    plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b1461a",
   "metadata": {},
   "source": [
    "## Run Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8627f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "train_and_eval(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ac31dc-38fa-40cd-a4a4-6481a0694626",
   "metadata": {},
   "source": [
    "# Homework challenges\n",
    "\n",
    "- Run the code for classification and regression\n",
    "- Change the learning rate and verify the performance in both the modes\n",
    "- Increase and descrease the number layers to see the performance change\n",
    "- Understand how dropout works by change the dropout rate. `DROPOUT_RATE = 0.0` means no dropout\n",
    "- Modify the code to run the experiments independently multiple times (changing the seed value) to compute the average performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0b662-444e-4d86-b558-33d5b01da2de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
