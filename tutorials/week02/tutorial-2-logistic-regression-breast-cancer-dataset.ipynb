{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:blue;\">Totorial 2 Coding Task: Logistic Regression on the Breast Cancer Dataset</h1>\n",
    "\n",
    "In this tutorial, we load the breast cancer data from `sklearn.datasets` and do classification using logistic regression with and without normalization to compute the average performance over 10 experiments. Further, we also do ridge and lasso regularizations to see if we can improve the performance. \n",
    "\n",
    "<h1 style=\"color:red;\">Intructions</h1>\n",
    "\n",
    "- Progress cell-by-cell.\n",
    "- Check for **<a style=\"color:red;\">Execute</a>s**, where codes for <a style=\"color:green;\">green</a> tasks are already written and you are expected write codes to excute the remaining tasks.\n",
    "- Check the exercises 2.1, 2.2, and 2.3 on Week 2 Ed lesson for help to complete the tasks.\n",
    "- After completing all the tasks, write your observations at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue;\">1) Load the dataset</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data description\n",
    "    \n",
    "The `load_breast_cancer` dataset in scikit-learn is a classic binary‐classification benchmark. It contains 569 tumor samples described by 30 real-valued features—computed from digitized images of fine needle aspirate (FNA) of breast masses—such as radius, texture, perimeter, area, and smoothness (each measured as mean, standard error, and “worst”/largest value). The task is to predict whether a tumor is malignant (212 samples) or benign (357 samples). Data shape:   \n",
    "\n",
    "- X: array of shape (569, 30)  \n",
    "- y: array of shape (569,), values in {0 = malignant, 1 = benign}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red;\">Execute:</h3>\n",
    "\n",
    "- <a style=\"color:green;\">Load the dataset to create X and y</a>\n",
    "- Print the shapes of X and y\n",
    "- Print the first 5 samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Write your code to print shapes X and y here\n",
    "\n",
    "\n",
    "# Write your code to print the first 5 samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue;\">2) Exploratory Data Analysis</h2>\n",
    "<h3 style=\"color:red;\">Execute</h3>\n",
    "\n",
    "- <a style=\"color:green;\">Load the data into a dataframe</a>\n",
    "- Compute the correlation between the columns in the data (features + target) \n",
    "- Print that correlation using `seaborn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load into DataFrame\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "# compute correlation matrix (including target)\n",
    "\n",
    "\n",
    "# optional: plot a heatmap\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:red;\">Execute</h3>\n",
    "\n",
    "- <a style=\"color:green;\">Plot an histogram of sample counts per class</a>\n",
    "- <a style=\"color:green;\">Pick a feature and plot its distribution per class</a>\n",
    "- change the following code to pick a different feature of your choice to plot its distribution per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the classes\n",
    "df['class']  = df['target'].map({0:'malignant', 1:'benign'})\n",
    "\n",
    "# Histogram of sample counts per class\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.countplot(x='class', data=df, hue='class', palette='Set2', legend=False)\n",
    "plt.title(\"Class distribution\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.show()\n",
    "\n",
    "# pick a feature, e.g. 'mean radius'\n",
    "feat = 'mean radius'\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(df, x=feat, hue='class',\n",
    "             element='step', stat='density',\n",
    "             common_norm=False, palette='Set1')\n",
    "plt.title(f\"Distribution of {feat} by class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue;\">3) Split the Data into 80/20 and Fit with 5-Fold Cross-Validation</h2>\n",
    "\n",
    "<h3 style=\"color:red;\">Execute</h3>\n",
    "\n",
    "- <a style=\"color:green;\">Split the dataset into 80% training and 20% testing data using `train_test_split`</a>\n",
    "- <a style=\"color:green;\">Fit a softmax regression model using 5-fold cross-validation</a>\n",
    "- Fit the model `clf` using `clf.fit` on the training data\n",
    "- Evaluate the model on the test data, that is, compute `y_pred`\n",
    "- Print test accuracy and confusion matrix\n",
    "\n",
    "**Note:** *We compute `cv_scores` before fitting the model because `cross_val_score` does its own fitting-and-scoring inside each fold, you actually pass it an unfitted estimator and let it call fit on every train-split behind the scenes. The final `.fit()` is only to produce your production model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train softmax regression model with 5-fold cross-validation\n",
    "clf = LogisticRegression(solver='saga', penalty=None, tol=1e-3, max_iter=1000)\n",
    "cv_scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean CV accuracy:\", np.mean(cv_scores))\n",
    "\n",
    "# Fit the model on the training data\n",
    "\n",
    "\n",
    "# Evaluate on the test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue;\">3) Compute average test performance without normalization</h2>\n",
    "\n",
    "We conduct 10 experiments without normalization and with different random seeds to compute the average performance on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct 10 experiments with different random seeds\n",
    "test_accuracies = []\n",
    "\n",
    "for seed in range(10):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Write you code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Test accuracies without normalization:\", test_accuracies)\n",
    "print(\"\\nMean test accuracy without normalization:\", np.mean(test_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue;\">4) Normalize the data to check if we get performance improvement</h2>\n",
    "\n",
    "<h3 style=\"color:red;\">Execute</h3>\n",
    "\n",
    "- Conduct 10 experiments with different random seeds. Normalize the dataset in each experiment using \n",
    "```python\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "**Note:** Under the hood, this is what happens:\n",
    "When you call  \n",
    "```python\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "```\n",
    "two things happen for each feature column $j$ of $X$:\n",
    "\n",
    "1. *Fit*  \n",
    "   Computes the sample mean  \n",
    "     $$\\mu_j = \\frac{1}{n_{\\rm train}}\\sum_{i=1}^{n_{\\rm train}}X_{i,j}$$\n",
    "   Computes the sample standard deviation  \n",
    "     $$\\sigma_j = \\sqrt{\\frac{1}{n_{\\rm train}}\\sum_{i=1}^{n_{\\rm train}}(X_{i,j}-\\mu_j)^2}$$\n",
    "\n",
    "2. *Transform* \n",
    "   Replaces each training value by  \n",
    "     \n",
    "     $$X'_{i,j} \\;=\\;\\frac{X_{i,j}-\\mu_j}{\\sigma_j},$$\n",
    "     so that the transformed column has zero mean and unit variance over the training set.\n",
    "\n",
    "When you later do  \n",
    "```python\n",
    "X_test = scaler.transform(X_test)\n",
    "```\n",
    "it uses the same $\\mu_j$ and $\\sigma_j$ learned from the training data to standardize the test features:\n",
    "$$\n",
    "X'_{\\rm test, i,j}\n",
    "=\\frac{X_{{\\rm test},i,j}-\\mu_j}{\\sigma_j}.\n",
    "$$\n",
    "This ensures your model sees test‐set features on the *exact* scale it was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct 10 experiments with different random seeds\n",
    "test_accuracies = []\n",
    "\n",
    "for seed in range(10):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "    # Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Test accuracies with normalization:\", test_accuracies)\n",
    "print(\"\\nMean test accuracy with normalization:\", np.mean(test_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue;\">5) Ridge and Lasso Regularization to Improve Performance</h2>\n",
    "\n",
    "We now apply ridge and lasso regularization to the softmax regression model in addition to normalization. Again, conduct 10 ex[eriments and compute the average accuracy.\n",
    "\n",
    "<h3 style=\"color:red;\">Execute</h3>\n",
    "\n",
    "- For the ridge regularization, change the penaty to l2 using `penalty = 'l2'`\n",
    "- For the lasso rregularization, change the penaty to l2 using `penalty = 'l1'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ridge_accuracies = []\n",
    "test_lasso_accuracies = []\n",
    "\n",
    "for seed in range(10):\n",
    "    np.random.seed(seed)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "    \n",
    "    # Write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean test accuracy with ridge penalty and normalization:\", np.mean(test_ridge_accuracies))\n",
    "print(\"Mean test accuracy with lasso penalty and normalization:\", np.mean(test_lasso_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:blue;\">6) Write at least four of your observations here</h2>\n",
    "\n",
    "- Obs 1:\n",
    "- Obs 2:\n",
    "- Obs 3:\n",
    "- Obs 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
